{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.drop(columns=['Message ID', 'Unnamed: 0', 'split'], inplace=True)\n",
    "\n",
    "df_val = pd.read_csv('val.csv')\n",
    "df_val.drop(columns=['Message ID', 'Unnamed: 0', 'split'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['Spam/Ham'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows: {len(df_train)}\")\n",
    "print(f\"Number of rows: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(\"\\nMissing values in training set:\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"\\nMissing values in validation set:\")\n",
    "print(df_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any NaN values with empty strings\n",
    "df_train['Subject'] = df_train['Subject'].fillna('')\n",
    "df_train['Message'] = df_train['Message'].fillna('')\n",
    "df_val['Subject'] = df_val['Subject'].fillna('')\n",
    "df_val['Message'] = df_val['Message'].fillna('')\n",
    "\n",
    "# Create Bag of Words vectorizer for text features\n",
    "bow = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Combine Subject and Message columns\n",
    "df_train['text'] = df_train['Subject'] + ' ' + df_train['Message']\n",
    "df_val['text'] = df_val['Subject'] + ' ' + df_val['Message']\n",
    "\n",
    "# Transform text data to BoW features\n",
    "X_train = bow.fit_transform(df_train['text'])\n",
    "X_val = bow.transform(df_val['text'])\n",
    "\n",
    "# Get labels\n",
    "y_train = df_train['Spam/Ham']\n",
    "y_val = df_val['Spam/Ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert sparse matrices to dense arrays properly\n",
    "# X_train = X_train.toarray()\n",
    "# y_train = np.array(y_train)\n",
    "# X_val = X_val.toarray()\n",
    "# y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Implement Multinomial Naive Bayes from scratch\n",
    "# class MultinomialNB:\n",
    "#     def __init__(self, alpha=1.0):\n",
    "#         self.alpha = alpha  # Laplace smoothing parameter\n",
    "#         self.class_priors = None\n",
    "#         self.feature_probs = None\n",
    "#         self.classes = None\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         # Check if X is empty or 1-dimensional\n",
    "#         if X.size == 0:\n",
    "#             raise ValueError(\"Input array X is empty\")\n",
    "#         if len(X.shape) == 1:\n",
    "#             X = X.reshape(1, -1)\n",
    "            \n",
    "#         # Get shape, handling both sparse and dense matrices\n",
    "#         n_samples = X.shape[0]\n",
    "#         n_features = X.shape[1]\n",
    "            \n",
    "#         self.classes = np.unique(y)\n",
    "#         n_classes = len(self.classes)\n",
    "        \n",
    "#         # Calculate class priors P(y)\n",
    "#         self.class_priors = np.zeros(n_classes)\n",
    "#         for i, c in enumerate(self.classes):\n",
    "#             self.class_priors[i] = np.sum(y == c) / n_samples\n",
    "            \n",
    "#         # Calculate feature probabilities P(x|y) with Laplace smoothing\n",
    "#         # Process one class at a time to reduce memory usage\n",
    "#         self.feature_probs = np.zeros((n_classes, n_features))\n",
    "#         for i, c in enumerate(self.classes):\n",
    "#             # Get indices of samples belonging to current class\n",
    "#             class_indices = np.where(y == c)[0]\n",
    "            \n",
    "#             # Calculate feature counts in batches\n",
    "#             feature_counts = np.zeros(n_features) + self.alpha\n",
    "#             batch_size = 1000  # Adjust based on available memory\n",
    "            \n",
    "#             for start_idx in range(0, len(class_indices), batch_size):\n",
    "#                 end_idx = min(start_idx + batch_size, len(class_indices))\n",
    "#                 batch_indices = class_indices[start_idx:end_idx]\n",
    "                \n",
    "#                 # Sum features for current batch\n",
    "#                 if isinstance(X, np.ndarray):\n",
    "#                     batch_sum = X[batch_indices].sum(axis=0)\n",
    "#                 else:\n",
    "#                     batch_sum = X[batch_indices].toarray().sum(axis=0)\n",
    "                    \n",
    "#                 feature_counts += batch_sum\n",
    "                \n",
    "#             total_counts = feature_counts.sum()\n",
    "#             self.feature_probs[i] = feature_counts / total_counts\n",
    "            \n",
    "#     def predict(self, X):\n",
    "#         # Handle 1-dimensional input\n",
    "#         if len(X.shape) == 1:\n",
    "#             X = X.reshape(1, -1)\n",
    "            \n",
    "#         # Predict in batches to save memory\n",
    "#         predictions = []\n",
    "#         batch_size = 1000  # Adjust based on available memory\n",
    "        \n",
    "#         for start_idx in range(0, X.shape[0], batch_size):\n",
    "#             end_idx = min(start_idx + batch_size, X.shape[0])\n",
    "#             if isinstance(X, np.ndarray):\n",
    "#                 batch = X[start_idx:end_idx]\n",
    "#             else:\n",
    "#                 batch = X[start_idx:end_idx].toarray()\n",
    "                \n",
    "#             batch_predictions = np.array([self._predict_single(x) for x in batch])\n",
    "#             predictions.extend(batch_predictions)\n",
    "            \n",
    "#         return np.array(predictions)\n",
    "    \n",
    "#     def _predict_single(self, x):\n",
    "#         # Calculate log probabilities to prevent numerical underflow\n",
    "#         log_probs = np.log(self.class_priors)\n",
    "        \n",
    "#         # Add log of feature probabilities where feature is present (x > 0)\n",
    "#         for i in range(len(self.classes)):\n",
    "#             # Only consider non-zero features to save computation\n",
    "#             present_features = x > 0\n",
    "#             if np.any(present_features):\n",
    "#                 # Multiply probability by feature count (for multinomial)\n",
    "#                 log_probs[i] += np.sum(np.log(self.feature_probs[i][present_features]) * x[present_features])\n",
    "        \n",
    "#         # Return class with highest probability\n",
    "#         return self.classes[np.argmax(log_probs)]\n",
    "\n",
    "# # Train the model\n",
    "# nb = MultinomialNB()\n",
    "# nb.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = nb.predict(X_val)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = np.mean(y_pred == y_val)\n",
    "# print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, Train Loss: 0.069341, Val Loss: 0.082843\n",
      "Iteration 200, Train Loss: 0.051172, Val Loss: 0.066666\n",
      "Iteration 300, Train Loss: 0.042308, Val Loss: 0.058775\n",
      "Iteration 400, Train Loss: 0.036779, Val Loss: 0.054015\n",
      "Iteration 500, Train Loss: 0.032902, Val Loss: 0.050866\n",
      "Iteration 600, Train Loss: 0.029997, Val Loss: 0.048658\n",
      "Iteration 700, Train Loss: 0.027706, Val Loss: 0.046986\n",
      "Iteration 800, Train Loss: 0.025842, Val Loss: 0.045672\n",
      "Iteration 900, Train Loss: 0.024283, Val Loss: 0.044613\n",
      "Iteration 1000, Train Loss: 0.022953, Val Loss: 0.043739\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 0.463076\n",
      "Final Loss: 0.022953\n",
      "Loss Reduction: 95.04%\n",
      "Total Iterations: 1000\n",
      "Validation Accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import sparse\n",
    "\n",
    "# class LogisticRegression:\n",
    "#     def __init__(self, learning_rate=0.01, max_iter=1000, batch_size=1000, tol=1e-6):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.max_iter = max_iter\n",
    "#         self.batch_size = batch_size\n",
    "#         self.tol = tol\n",
    "#         self.weights = None\n",
    "#         self.bias = None\n",
    "#         self.loss_history = []  # Thm  lu loss qua cc iteration\n",
    "        \n",
    "#     def _sigmoid(self, z):\n",
    "#         # Clip z  trnh overflow\n",
    "#         z = np.clip(z, -250, 250)\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     def _get_batches(self, X, y, batch_size):\n",
    "#         \"\"\"Generator  chia d liu thnh batches\"\"\"\n",
    "#         n_samples = X.shape[0]\n",
    "#         for i in range(0, n_samples, batch_size):\n",
    "#             end_idx = min(i + batch_size, n_samples)\n",
    "#             if sparse.issparse(X):\n",
    "#                 yield X[i:end_idx], y[i:end_idx]\n",
    "#             else:\n",
    "#                 yield X[i:end_idx], y[i:end_idx]\n",
    "    \n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         # Convert labels to 0/1 if they're strings\n",
    "#         if isinstance(y.iloc[0], str):\n",
    "#             y = (y == 'spam').astype(int)\n",
    "        \n",
    "#         # Convert validation labels if provided\n",
    "#         if X_val is not None and y_val is not None:\n",
    "#             if isinstance(y_val.iloc[0], str):\n",
    "#                 y_val = (y_val == 'spam').astype(int)\n",
    "#             if hasattr(y_val, 'values'):\n",
    "#                 y_val = y_val.values\n",
    "        \n",
    "#         n_samples, n_features = X.shape\n",
    "        \n",
    "#         # Initialize weights v bias\n",
    "#         self.weights = np.zeros(n_features)\n",
    "#         self.bias = 0\n",
    "        \n",
    "#         # Convert to numpy array if needed\n",
    "#         if hasattr(y, 'values'):\n",
    "#             y = y.values\n",
    "            \n",
    "#         prev_cost = float('inf')\n",
    "#         self.loss_history = []  # Reset loss history\n",
    "#         self.val_loss_history = []  # Thm validation loss history\n",
    "        \n",
    "#         for iteration in range(self.max_iter):\n",
    "#             total_cost = 0\n",
    "#             n_batches = 0\n",
    "            \n",
    "#             # Shuffle indices for each epoch\n",
    "#             indices = np.random.permutation(n_samples)\n",
    "#             if sparse.issparse(X):\n",
    "#                 X_shuffled = X[indices]\n",
    "#             else:\n",
    "#                 X_shuffled = X[indices]\n",
    "#             y_shuffled = y[indices]\n",
    "            \n",
    "#             # Process each batch\n",
    "#             for X_batch, y_batch in self._get_batches(X_shuffled, y_shuffled, self.batch_size):\n",
    "#                 batch_size = X_batch.shape[0]\n",
    "                \n",
    "#                 # Forward pass\n",
    "#                 if sparse.issparse(X_batch):\n",
    "#                     z = X_batch.dot(self.weights) + self.bias\n",
    "#                 else:\n",
    "#                     z = np.dot(X_batch, self.weights) + self.bias\n",
    "                \n",
    "#                 predictions = self._sigmoid(z)\n",
    "                \n",
    "#                 # Compute cost for this batch\n",
    "#                 epsilon = 1e-15  #  trnh log(0)\n",
    "#                 predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "#                 batch_cost = -np.mean(y_batch * np.log(predictions) + \n",
    "#                                     (1 - y_batch) * np.log(1 - predictions))\n",
    "#                 total_cost += batch_cost * batch_size\n",
    "#                 n_batches += batch_size\n",
    "                \n",
    "#                 # Compute gradients\n",
    "#                 dz = predictions - y_batch\n",
    "#                 if sparse.issparse(X_batch):\n",
    "#                     dw = X_batch.T.dot(dz) / batch_size\n",
    "#                 else:\n",
    "#                     dw = np.dot(X_batch.T, dz) / batch_size\n",
    "#                 db = np.mean(dz)\n",
    "                \n",
    "#                 # Update weights v bias\n",
    "#                 self.weights -= self.learning_rate * dw\n",
    "#                 self.bias -= self.learning_rate * db\n",
    "            \n",
    "#             # Average cost across all batches\n",
    "#             avg_cost = total_cost / n_batches\n",
    "#             self.loss_history.append(avg_cost)\n",
    "            \n",
    "#             # Calculate validation loss if validation data is provided\n",
    "#             if X_val is not None and y_val is not None:\n",
    "#                 val_loss = self._calculate_loss(X_val, y_val)\n",
    "#                 self.val_loss_history.append(val_loss)\n",
    "            \n",
    "#             # Check for convergence\n",
    "#             if abs(prev_cost - avg_cost) < self.tol:\n",
    "#                 print(f\"Converged at iteration {iteration + 1}\")\n",
    "#                 break\n",
    "                \n",
    "#             prev_cost = avg_cost\n",
    "            \n",
    "#             if (iteration + 1) % 100 == 0:\n",
    "#                 val_info = f\", Val Loss: {self.val_loss_history[-1]:.6f}\" if X_val is not None else \"\"\n",
    "#                 print(f\"Iteration {iteration + 1}, Train Loss: {avg_cost:.6f}{val_info}\")\n",
    "    \n",
    "#     def _calculate_loss(self, X, y):\n",
    "#         \"\"\"Calculate loss for given data\"\"\"\n",
    "#         if sparse.issparse(X):\n",
    "#             z = X.dot(self.weights) + self.bias\n",
    "#         else:\n",
    "#             z = np.dot(X, self.weights) + self.bias\n",
    "        \n",
    "#         predictions = self._sigmoid(z)\n",
    "#         epsilon = 1e-15\n",
    "#         predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "        \n",
    "#         return -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "    \n",
    "#     def predict_proba(self, X):\n",
    "#         \"\"\"Predict probabilities with batch processing\"\"\"\n",
    "#         n_samples = X.shape[0]\n",
    "#         probabilities = np.zeros(n_samples)\n",
    "        \n",
    "#         start_idx = 0\n",
    "#         for X_batch, _ in self._get_batches(X, np.zeros(n_samples), self.batch_size):\n",
    "#             batch_size = X_batch.shape[0]\n",
    "            \n",
    "#             if sparse.issparse(X_batch):\n",
    "#                 z = X_batch.dot(self.weights) + self.bias\n",
    "#             else:\n",
    "#                 z = np.dot(X_batch, self.weights) + self.bias\n",
    "            \n",
    "#             batch_proba = self._sigmoid(z)\n",
    "#             probabilities[start_idx:start_idx + batch_size] = batch_proba\n",
    "#             start_idx += batch_size\n",
    "            \n",
    "#         return probabilities\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         \"\"\"Predict with batch processing\"\"\"\n",
    "#         probabilities = self.predict_proba(X)\n",
    "#         return (probabilities >= 0.5).astype(int)\n",
    "    \n",
    "#     def plot_loss(self, figsize=(12, 5)):\n",
    "#         \"\"\"Visualize training loss\"\"\"\n",
    "#         if not self.loss_history:\n",
    "#             print(\"No loss history available. Train the model first.\")\n",
    "#             return\n",
    "        \n",
    "#         if len(self.val_loss_history) > 0:\n",
    "#             # Plot both training and validation loss\n",
    "#             fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "            \n",
    "#             # Training and validation loss\n",
    "#             ax1.plot(self.loss_history, label='Training Loss', color='blue', linewidth=2)\n",
    "#             ax1.plot(self.val_loss_history, label='Validation Loss', color='red', linewidth=2)\n",
    "#             ax1.set_xlabel('Iteration')\n",
    "#             ax1.set_ylabel('Loss')\n",
    "#             ax1.set_title('Training vs Validation Loss')\n",
    "#             ax1.legend()\n",
    "#             ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "#             # Log scale plot\n",
    "#             ax2.semilogy(self.loss_history, label='Training Loss', color='blue', linewidth=2)\n",
    "#             ax2.semilogy(self.val_loss_history, label='Validation Loss', color='red', linewidth=2)\n",
    "#             ax2.set_xlabel('Iteration')\n",
    "#             ax2.set_ylabel('Loss (log scale)')\n",
    "#             ax2.set_title('Loss Convergence (Log Scale)')\n",
    "#             ax2.legend()\n",
    "#             ax2.grid(True, alpha=0.3)\n",
    "#         else:\n",
    "#             # Plot only training loss\n",
    "#             fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "            \n",
    "#             # Normal scale\n",
    "#             ax1.plot(self.loss_history, color='blue', linewidth=2)\n",
    "#             ax1.set_xlabel('Iteration')\n",
    "#             ax1.set_ylabel('Loss')\n",
    "#             ax1.set_title('Training Loss')\n",
    "#             ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "#             # Log scale\n",
    "#             ax2.semilogy(self.loss_history, color='blue', linewidth=2)\n",
    "#             ax2.set_xlabel('Iteration')\n",
    "#             ax2.set_ylabel('Loss (log scale)')\n",
    "#             ax2.set_title('Training Loss (Log Scale)')\n",
    "#             ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Print some statistics\n",
    "#         print(f\"Initial Loss: {self.loss_history[0]:.6f}\")\n",
    "#         print(f\"Final Loss: {self.loss_history[-1]:.6f}\")\n",
    "#         print(f\"Loss Reduction: {((self.loss_history[0] - self.loss_history[-1]) / self.loss_history[0] * 100):.2f}%\")\n",
    "#         print(f\"Total Iterations: {len(self.loss_history)}\")\n",
    "\n",
    "# model = LogisticRegression(learning_rate=0.1, max_iter=1000, batch_size=1000)\n",
    "# model.fit(X_train, y_train, X_val, y_val)\n",
    "# # Visualize loss\n",
    "# model.plot_loss()\n",
    "# # Predict \n",
    "# y_pred_train = model.predict(X_train)\n",
    "# y_pred_val = model.predict(X_val)\n",
    "# y_proba_val = model.predict_proba(X_val)\n",
    "# # Calculate accuracy\n",
    "# train_accuracy = np.mean(y_pred_train == (y_train == 'spam').astype(int))\n",
    "# val_accuracy = np.mean(y_pred_val == (y_val == 'spam').astype(int))\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XGBoost training with 100 estimators...\n",
      "Data shape: (27284, 139888), Sparse: True\n",
      "Base prediction: 0.0317\n",
      "Training estimator 5/100\n",
      "Iteration 5: Train Loss: 0.642857, Val Loss: 0.644666\n",
      "Training estimator 10/100\n",
      "Iteration 10: Train Loss: 0.595521, Val Loss: 0.598827\n",
      "Training estimator 15/100\n",
      "Iteration 15: Train Loss: 0.529122, Val Loss: 0.534305\n",
      "Training estimator 20/100\n",
      "Iteration 20: Train Loss: 0.488605, Val Loss: 0.494512\n",
      "Training estimator 25/100\n",
      "Iteration 25: Train Loss: 0.453084, Val Loss: 0.460635\n",
      "Training estimator 30/100\n",
      "Iteration 30: Train Loss: 0.418734, Val Loss: 0.426981\n",
      "Training estimator 35/100\n",
      "Iteration 35: Train Loss: 0.403319, Val Loss: 0.410493\n",
      "Training estimator 40/100\n",
      "Iteration 40: Train Loss: 0.388989, Val Loss: 0.395472\n",
      "Training estimator 45/100\n",
      "Iteration 45: Train Loss: 0.369602, Val Loss: 0.374232\n",
      "Training estimator 50/100\n",
      "Iteration 50: Train Loss: 0.354926, Val Loss: 0.358272\n",
      "Training estimator 55/100\n",
      "Iteration 55: Train Loss: 0.338628, Val Loss: 0.343139\n",
      "Training estimator 60/100\n",
      "Iteration 60: Train Loss: 0.318702, Val Loss: 0.323724\n",
      "Training estimator 65/100\n",
      "Iteration 65: Train Loss: 0.309260, Val Loss: 0.315343\n",
      "Training estimator 70/100\n",
      "Iteration 70: Train Loss: 0.291738, Val Loss: 0.298161\n",
      "Training estimator 75/100\n",
      "Iteration 75: Train Loss: 0.273957, Val Loss: 0.280563\n",
      "Training estimator 80/100\n",
      "Iteration 80: Train Loss: 0.261583, Val Loss: 0.268252\n",
      "Training estimator 85/100\n",
      "Iteration 85: Train Loss: 0.249584, Val Loss: 0.256959\n",
      "Training estimator 90/100\n",
      "Iteration 90: Train Loss: 0.240976, Val Loss: 0.249765\n",
      "Training estimator 95/100\n",
      "Iteration 95: Train Loss: 0.234648, Val Loss: 0.243746\n",
      "Training estimator 100/100\n",
      "Iteration 100: Train Loss: 0.224035, Val Loss: 0.232684\n",
      "Training completed!\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "Improved XGBoost Results:\n",
      "Validation Accuracy: 0.9394\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from scipy import sparse\n",
    "# from collections import defaultdict\n",
    "# import random\n",
    "\n",
    "# class TreeNode:\n",
    "#     def __init__(self):\n",
    "#         self.feature_idx = None\n",
    "#         self.threshold = None\n",
    "#         self.left = None\n",
    "#         self.right = None\n",
    "#         self.value = None\n",
    "#         self.is_leaf = False\n",
    "        \n",
    "# class XGBoostTree:\n",
    "#     def __init__(self, max_depth=3, min_child_weight=0.1, reg_lambda=1.0, \n",
    "#                  reg_alpha=0.0, gamma=0.0, colsample_bytree=1.0):\n",
    "#         self.max_depth = max_depth\n",
    "#         self.min_child_weight = min_child_weight\n",
    "#         self.reg_lambda = reg_lambda\n",
    "#         self.reg_alpha = reg_alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.colsample_bytree = colsample_bytree\n",
    "#         self.root = None\n",
    "#         self.feature_indices = None\n",
    "        \n",
    "#     def _calculate_leaf_weight(self, gradients, hessians):\n",
    "#         \"\"\"Calculate optimal leaf weight using Newton-Raphson\"\"\"\n",
    "#         grad_sum = np.sum(gradients)\n",
    "#         hess_sum = np.sum(hessians)\n",
    "        \n",
    "#         if hess_sum == 0:\n",
    "#             return 0\n",
    "            \n",
    "#         weight = -grad_sum / (hess_sum + self.reg_lambda)\n",
    "        \n",
    "#         # Apply L1 regularization (soft thresholding)\n",
    "#         if self.reg_alpha > 0:\n",
    "#             if weight > self.reg_alpha:\n",
    "#                 weight -= self.reg_alpha\n",
    "#             elif weight < -self.reg_alpha:\n",
    "#                 weight += self.reg_alpha\n",
    "#             else:\n",
    "#                 weight = 0\n",
    "                \n",
    "#         return weight\n",
    "    \n",
    "#     def _calculate_gain(self, left_grad, left_hess, right_grad, right_hess, parent_grad, parent_hess):\n",
    "#         \"\"\"Calculate gain from split\"\"\"\n",
    "#         def calculate_score(grad_sum, hess_sum):\n",
    "#             if hess_sum == 0:\n",
    "#                 return 0\n",
    "#             return (grad_sum ** 2) / (hess_sum + self.reg_lambda)\n",
    "        \n",
    "#         left_score = calculate_score(left_grad, left_hess)\n",
    "#         right_score = calculate_score(right_grad, right_hess)\n",
    "#         parent_score = calculate_score(parent_grad, parent_hess)\n",
    "        \n",
    "#         gain = 0.5 * (left_score + right_score - parent_score) - self.gamma\n",
    "#         return gain\n",
    "    \n",
    "#     def _get_feature_column_sparse(self, X, feature_idx):\n",
    "#         \"\"\"Efficiently get feature column from sparse matrix\"\"\"\n",
    "#         if sparse.issparse(X):\n",
    "#             return X[:, feature_idx].toarray().flatten()\n",
    "#         else:\n",
    "#             return X[:, feature_idx]\n",
    "    \n",
    "#     def _find_best_split(self, X, gradients, hessians):\n",
    "#         \"\"\"Find best split for current node - memory efficient version\"\"\"\n",
    "#         best_gain = -float('inf')\n",
    "#         best_feature = None\n",
    "#         best_threshold = None\n",
    "#         best_left_indices = None\n",
    "#         best_right_indices = None\n",
    "        \n",
    "#         n_samples, n_features = X.shape\n",
    "        \n",
    "#         # Sample features for this tree (column sampling) - more aggressive\n",
    "#         if self.feature_indices is None:\n",
    "#             n_features_sample = max(1, int(n_features * self.colsample_bytree))\n",
    "#             # Allow more features but still limit for memory\n",
    "#             n_features_sample = min(n_features_sample, 500)  # Increased from 100\n",
    "#             self.feature_indices = np.random.choice(n_features, n_features_sample, replace=False)\n",
    "        \n",
    "#         # Try each sampled feature\n",
    "#         for feature_idx in self.feature_indices:\n",
    "#             # Get feature values efficiently\n",
    "#             feature_values = self._get_feature_column_sparse(X, feature_idx)\n",
    "            \n",
    "#             # Skip if all values are the same\n",
    "#             if len(np.unique(feature_values)) <= 1:\n",
    "#                 continue\n",
    "            \n",
    "#             # More thresholds for better splits\n",
    "#             unique_values = np.unique(feature_values)\n",
    "#             if len(unique_values) > 20:\n",
    "#                 # Use more quantiles for better splits\n",
    "#                 percentiles = np.linspace(5, 95, 19)  # More percentiles\n",
    "#                 thresholds = np.percentile(unique_values, percentiles)\n",
    "#                 thresholds = np.unique(thresholds)\n",
    "#             elif len(unique_values) > 10:\n",
    "#                 # Use all unique values for medium-sized sets\n",
    "#                 thresholds = unique_values[:-1]\n",
    "#             else:\n",
    "#                 thresholds = unique_values[:-1]\n",
    "            \n",
    "#             for threshold in thresholds:\n",
    "#                 # Split samples\n",
    "#                 left_mask = feature_values <= threshold\n",
    "#                 right_mask = ~left_mask\n",
    "                \n",
    "#                 # Check minimum child weight constraint\n",
    "#                 left_hess_sum = np.sum(hessians[left_mask])\n",
    "#                 right_hess_sum = np.sum(hessians[right_mask])\n",
    "                \n",
    "#                 if left_hess_sum < self.min_child_weight or right_hess_sum < self.min_child_weight:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Calculate gain\n",
    "#                 left_grad_sum = np.sum(gradients[left_mask])\n",
    "#                 right_grad_sum = np.sum(gradients[right_mask])\n",
    "#                 parent_grad_sum = np.sum(gradients)\n",
    "#                 parent_hess_sum = np.sum(hessians)\n",
    "                \n",
    "#                 gain = self._calculate_gain(left_grad_sum, left_hess_sum,\n",
    "#                                           right_grad_sum, right_hess_sum,\n",
    "#                                           parent_grad_sum, parent_hess_sum)\n",
    "                \n",
    "#                 if gain > best_gain:\n",
    "#                     best_gain = gain\n",
    "#                     best_feature = feature_idx\n",
    "#                     best_threshold = threshold\n",
    "#                     best_left_indices = np.where(left_mask)[0]\n",
    "#                     best_right_indices = np.where(right_mask)[0]\n",
    "        \n",
    "#         return best_gain, best_feature, best_threshold, best_left_indices, best_right_indices\n",
    "    \n",
    "#     def _build_tree(self, X, gradients, hessians, depth=0, indices=None):\n",
    "#         \"\"\"Recursively build tree - memory efficient version\"\"\"\n",
    "#         if indices is None:\n",
    "#             indices = np.arange(len(gradients))\n",
    "        \n",
    "#         node = TreeNode()\n",
    "        \n",
    "#         # Check stopping criteria\n",
    "#         if (depth >= self.max_depth or \n",
    "#             len(indices) <= 1 or \n",
    "#             np.sum(hessians[indices]) < self.min_child_weight):\n",
    "            \n",
    "#             # Create leaf node\n",
    "#             node.is_leaf = True\n",
    "#             node.value = self._calculate_leaf_weight(gradients[indices], hessians[indices])\n",
    "#             return node\n",
    "        \n",
    "#         # Get subset of data for current node\n",
    "#         if sparse.issparse(X):\n",
    "#             X_subset = X[indices]\n",
    "#         else:\n",
    "#             X_subset = X[indices]\n",
    "#         grad_subset = gradients[indices]\n",
    "#         hess_subset = hessians[indices]\n",
    "        \n",
    "#         # Find best split\n",
    "#         gain, feature_idx, threshold, left_rel_indices, right_rel_indices = \\\n",
    "#             self._find_best_split(X_subset, grad_subset, hess_subset)\n",
    "        \n",
    "#         # If no good split found, create leaf\n",
    "#         if gain <= 0 or feature_idx is None:\n",
    "#             node.is_leaf = True\n",
    "#             node.value = self._calculate_leaf_weight(grad_subset, hess_subset)\n",
    "#             return node\n",
    "        \n",
    "#         # Create internal node\n",
    "#         node.feature_idx = feature_idx\n",
    "#         node.threshold = threshold\n",
    "        \n",
    "#         # Convert relative indices back to absolute indices\n",
    "#         left_indices = indices[left_rel_indices]\n",
    "#         right_indices = indices[right_rel_indices]\n",
    "        \n",
    "#         # Recursively build left and right subtrees\n",
    "#         node.left = self._build_tree(X, gradients, hessians, depth + 1, left_indices)\n",
    "#         node.right = self._build_tree(X, gradients, hessians, depth + 1, right_indices)\n",
    "        \n",
    "#         return node\n",
    "    \n",
    "#     def fit(self, X, gradients, hessians):\n",
    "#         \"\"\"Fit tree to gradients and hessians\"\"\"\n",
    "#         self.root = self._build_tree(X, gradients, hessians)\n",
    "    \n",
    "#     def _predict_single_sparse(self, x_sparse, node):\n",
    "#         \"\"\"Predict single sparse sample recursively\"\"\"\n",
    "#         if node.is_leaf:\n",
    "#             return node.value\n",
    "        \n",
    "#         # Get feature value from sparse vector\n",
    "#         if sparse.issparse(x_sparse):\n",
    "#             feature_value = x_sparse[0, node.feature_idx]\n",
    "#         else:\n",
    "#             feature_value = x_sparse[node.feature_idx]\n",
    "        \n",
    "#         if feature_value <= node.threshold:\n",
    "#             return self._predict_single_sparse(x_sparse, node.left)\n",
    "#         else:\n",
    "#             return self._predict_single_sparse(x_sparse, node.right)\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         \"\"\"Predict for multiple samples - memory efficient\"\"\"\n",
    "#         predictions = np.zeros(X.shape[0])\n",
    "        \n",
    "#         if sparse.issparse(X):\n",
    "#             # Process sparse matrix row by row to save memory\n",
    "#             for i in range(X.shape[0]):\n",
    "#                 x_row = X[i:i+1]  # Keep as sparse\n",
    "#                 predictions[i] = self._predict_single_sparse(x_row, self.root)\n",
    "#         else:\n",
    "#             for i, x in enumerate(X):\n",
    "#                 predictions[i] = self._predict_single_sparse(x, self.root)\n",
    "        \n",
    "#         return predictions\n",
    "\n",
    "# class XGBoost:\n",
    "#     def __init__(self, n_estimators=50, learning_rate=0.3, max_depth=6, \n",
    "#                  min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "#                  reg_lambda=0.1, reg_alpha=0.0, gamma=0.0, \n",
    "#                  early_stopping_rounds=None, eval_metric='logloss',\n",
    "#                  batch_size=500, random_state=42):\n",
    "        \n",
    "#         # Reduced defaults for memory efficiency\n",
    "#         self.n_estimators = n_estimators\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.max_depth = max_depth\n",
    "#         self.min_child_weight = min_child_weight\n",
    "#         self.subsample = subsample\n",
    "#         self.colsample_bytree = colsample_bytree\n",
    "#         self.reg_lambda = reg_lambda\n",
    "#         self.reg_alpha = reg_alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.early_stopping_rounds = early_stopping_rounds\n",
    "#         self.eval_metric = eval_metric\n",
    "#         self.batch_size = batch_size\n",
    "#         self.random_state = random_state\n",
    "        \n",
    "#         self.trees = []\n",
    "#         self.base_prediction = 0\n",
    "#         self.train_scores = []\n",
    "#         self.val_scores = []\n",
    "#         self.best_iteration = 0\n",
    "        \n",
    "#         # Set random seed\n",
    "#         np.random.seed(random_state)\n",
    "#         random.seed(random_state)\n",
    "        \n",
    "#     def _sigmoid(self, z):\n",
    "#         \"\"\"Sigmoid function with overflow protection\"\"\"\n",
    "#         z = np.clip(z, -250, 250)\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     def _compute_gradients_hessians(self, y_true, y_pred):\n",
    "#         \"\"\"Compute gradients and hessians for logistic loss\"\"\"\n",
    "#         p = self._sigmoid(y_pred)\n",
    "#         gradients = p - y_true\n",
    "#         hessians = p * (1 - p)\n",
    "#         hessians = np.maximum(hessians, 1e-16)\n",
    "#         return gradients, hessians\n",
    "    \n",
    "#     def _compute_loss(self, y_true, y_pred):\n",
    "#         \"\"\"Compute logistic loss\"\"\"\n",
    "#         p = self._sigmoid(y_pred)\n",
    "#         epsilon = 1e-15\n",
    "#         p = np.clip(p, epsilon, 1 - epsilon)\n",
    "#         return -np.mean(y_true * np.log(p) + (1 - y_true) * np.log(1 - p))\n",
    "    \n",
    "#     def _get_batches(self, X, y=None, batch_size=None):\n",
    "#         \"\"\"Generator  chia d liu thnh batches\"\"\"\n",
    "#         if batch_size is None:\n",
    "#             batch_size = self.batch_size\n",
    "            \n",
    "#         n_samples = X.shape[0]\n",
    "#         for i in range(0, n_samples, batch_size):\n",
    "#             end_idx = min(i + batch_size, n_samples)\n",
    "#             if y is not None:\n",
    "#                 yield X[i:end_idx], y[i:end_idx]\n",
    "#             else:\n",
    "#                 yield X[i:end_idx]\n",
    "    \n",
    "#     def fit(self, X_train, y_train, X_val=None, y_val=None, verbose=True):\n",
    "#         \"\"\"Fit XGBoost model - memory efficient version\"\"\"\n",
    "#         # Convert labels to 0/1 if they're strings\n",
    "#         if hasattr(y_train, 'iloc') and isinstance(y_train.iloc[0], str):\n",
    "#             y_train = (y_train == 'spam').astype(int)\n",
    "#         if hasattr(y_train, 'values'):\n",
    "#             y_train = y_train.values\n",
    "            \n",
    "#         if X_val is not None and y_val is not None:\n",
    "#             if hasattr(y_val, 'iloc') and isinstance(y_val.iloc[0], str):\n",
    "#                 y_val = (y_val == 'spam').astype(int)\n",
    "#             if hasattr(y_val, 'values'):\n",
    "#                 y_val = y_val.values\n",
    "        \n",
    "#         n_samples = X_train.shape[0]\n",
    "        \n",
    "#         # Initialize base prediction (log odds)\n",
    "#         pos_rate = np.mean(y_train)\n",
    "#         pos_rate = np.clip(pos_rate, 1e-15, 1 - 1e-15)\n",
    "#         self.base_prediction = np.log(pos_rate / (1 - pos_rate))\n",
    "        \n",
    "#         # Initialize predictions\n",
    "#         train_predictions = np.full(n_samples, self.base_prediction)\n",
    "#         if X_val is not None:\n",
    "#             val_predictions = np.full(X_val.shape[0], self.base_prediction)\n",
    "        \n",
    "#         if verbose:\n",
    "#             print(f\"Starting XGBoost training with {self.n_estimators} estimators...\")\n",
    "#             print(f\"Data shape: {X_train.shape}, Sparse: {sparse.issparse(X_train)}\")\n",
    "#             print(f\"Base prediction: {self.base_prediction:.4f}\")\n",
    "        \n",
    "#         best_val_score = float('inf')\n",
    "#         no_improvement_count = 0\n",
    "        \n",
    "#         for estimator_idx in range(self.n_estimators):\n",
    "#             if verbose and (estimator_idx + 1) % 5 == 0:\n",
    "#                 print(f\"Training estimator {estimator_idx + 1}/{self.n_estimators}\")\n",
    "            \n",
    "#             # Compute gradients and hessians\n",
    "#             gradients, hessians = self._compute_gradients_hessians(y_train, train_predictions)\n",
    "            \n",
    "#             # Row sampling (subsample) - less aggressive for better learning\n",
    "#             if self.subsample < 1.0:\n",
    "#                 n_subsample = int(n_samples * self.subsample)\n",
    "#                 # Increase subsample size for better learning\n",
    "#                 n_subsample = min(n_subsample, 8000)  # Increased from 5000\n",
    "#                 sample_indices = np.random.choice(n_samples, n_subsample, replace=False)\n",
    "                \n",
    "#                 X_subsample = X_train[sample_indices]\n",
    "#                 gradients_subsample = gradients[sample_indices]\n",
    "#                 hessians_subsample = hessians[sample_indices]\n",
    "#             else:\n",
    "#                 # Allow larger sample size for better learning\n",
    "#                 if n_samples > 8000:  # Increased from 5000\n",
    "#                     sample_indices = np.random.choice(n_samples, 8000, replace=False)\n",
    "#                     X_subsample = X_train[sample_indices]\n",
    "#                     gradients_subsample = gradients[sample_indices]\n",
    "#                     hessians_subsample = hessians[sample_indices]\n",
    "#                 else:\n",
    "#                     X_subsample = X_train\n",
    "#                     gradients_subsample = gradients\n",
    "#                     hessians_subsample = hessians\n",
    "            \n",
    "#             # Create and fit tree\n",
    "#             tree = XGBoostTree(\n",
    "#                 max_depth=self.max_depth,\n",
    "#                 min_child_weight=self.min_child_weight,\n",
    "#                 reg_lambda=self.reg_lambda,\n",
    "#                 reg_alpha=self.reg_alpha,\n",
    "#                 gamma=self.gamma,\n",
    "#                 colsample_bytree=self.colsample_bytree\n",
    "#             )\n",
    "            \n",
    "#             tree.fit(X_subsample, gradients_subsample, hessians_subsample)\n",
    "#             self.trees.append(tree)\n",
    "            \n",
    "#             # Update predictions using batch processing\n",
    "#             # Training predictions\n",
    "#             start_idx = 0\n",
    "#             for X_batch in self._get_batches(X_train, batch_size=self.batch_size):\n",
    "#                 batch_size = X_batch.shape[0]\n",
    "#                 tree_pred = tree.predict(X_batch)\n",
    "#                 train_predictions[start_idx:start_idx + batch_size] += self.learning_rate * tree_pred\n",
    "#                 start_idx += batch_size\n",
    "            \n",
    "#             # Validation predictions\n",
    "#             if X_val is not None:\n",
    "#                 start_idx = 0\n",
    "#                 for X_batch in self._get_batches(X_val, batch_size=self.batch_size):\n",
    "#                     batch_size = X_batch.shape[0]\n",
    "#                     tree_pred = tree.predict(X_batch)\n",
    "#                     val_predictions[start_idx:start_idx + batch_size] += self.learning_rate * tree_pred\n",
    "#                     start_idx += batch_size\n",
    "            \n",
    "#             # Compute and store scores\n",
    "#             train_loss = self._compute_loss(y_train, train_predictions)\n",
    "#             self.train_scores.append(train_loss)\n",
    "            \n",
    "#             if X_val is not None:\n",
    "#                 val_loss = self._compute_loss(y_val, val_predictions)\n",
    "#                 self.val_scores.append(val_loss)\n",
    "                \n",
    "#                 # Early stopping\n",
    "#                 if self.early_stopping_rounds is not None:\n",
    "#                     if val_loss < best_val_score:\n",
    "#                         best_val_score = val_loss\n",
    "#                         self.best_iteration = estimator_idx\n",
    "#                         no_improvement_count = 0\n",
    "#                     else:\n",
    "#                         no_improvement_count += 1\n",
    "                        \n",
    "#                     if no_improvement_count >= self.early_stopping_rounds:\n",
    "#                         if verbose:\n",
    "#                             print(f\"Early stopping at iteration {estimator_idx + 1}\")\n",
    "#                             print(f\"Best iteration: {self.best_iteration + 1}\")\n",
    "#                         break\n",
    "                \n",
    "#                 if verbose and (estimator_idx + 1) % 5 == 0:\n",
    "#                     print(f\"Iteration {estimator_idx + 1}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "#             else:\n",
    "#                 if verbose and (estimator_idx + 1) % 5 == 0:\n",
    "#                     print(f\"Iteration {estimator_idx + 1}: Train Loss: {train_loss:.6f}\")\n",
    "        \n",
    "#         if verbose:\n",
    "#             print(\"Training completed!\")\n",
    "    \n",
    "#     def predict_proba(self, X):\n",
    "#         \"\"\"Predict probabilities with batch processing\"\"\"\n",
    "#         n_samples = X.shape[0]\n",
    "#         predictions = np.full(n_samples, self.base_prediction)\n",
    "        \n",
    "#         # Determine how many trees to use (for early stopping)\n",
    "#         n_trees_to_use = len(self.trees)\n",
    "#         if (self.early_stopping_rounds is not None and \n",
    "#             hasattr(self, 'best_iteration') and \n",
    "#             self.best_iteration < len(self.trees)):\n",
    "#             n_trees_to_use = self.best_iteration + 1\n",
    "        \n",
    "#         # Add predictions from each tree using batch processing\n",
    "#         for i, tree in enumerate(self.trees[:n_trees_to_use]):\n",
    "#             start_idx = 0\n",
    "#             for X_batch in self._get_batches(X, batch_size=self.batch_size):\n",
    "#                 batch_size = X_batch.shape[0]\n",
    "#                 tree_pred = tree.predict(X_batch)\n",
    "#                 predictions[start_idx:start_idx + batch_size] += self.learning_rate * tree_pred\n",
    "#                 start_idx += batch_size\n",
    "        \n",
    "#         # Convert to probabilities\n",
    "#         probabilities = self._sigmoid(predictions)\n",
    "#         return probabilities\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         \"\"\"Predict with batch processing\"\"\"\n",
    "#         probabilities = self.predict_proba(X)\n",
    "#         return (probabilities >= 0.5).astype(int)\n",
    "    \n",
    "#     def get_feature_importance(self, importance_type='gain'):\n",
    "#         \"\"\"Get feature importance (simplified version)\"\"\"\n",
    "#         feature_importance = defaultdict(float)\n",
    "        \n",
    "#         for tree in self.trees:\n",
    "#             self._traverse_tree_for_importance(tree.root, feature_importance)\n",
    "        \n",
    "#         return dict(feature_importance)\n",
    "    \n",
    "#     def _traverse_tree_for_importance(self, node, importance_dict):\n",
    "#         \"\"\"Traverse tree to calculate feature importance\"\"\"\n",
    "#         if node is None or node.is_leaf:\n",
    "#             return\n",
    "        \n",
    "#         importance_dict[node.feature_idx] += 1\n",
    "        \n",
    "#         self._traverse_tree_for_importance(node.left, importance_dict)\n",
    "#         self._traverse_tree_for_importance(node.right, importance_dict)\n",
    "\n",
    "# xgb_model = XGBoost(\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.3,    \n",
    "#     max_depth=6,           \n",
    "#     min_child_weight=0.1,  \n",
    "#     subsample=0.8,         \n",
    "#     colsample_bytree=0.8,  \n",
    "#     reg_lambda=0.1,        \n",
    "#     reg_alpha=0.0,\n",
    "#     gamma=0.0,\n",
    "#     early_stopping_rounds=10,\n",
    "#     batch_size=1000,\n",
    "#     random_state=42\n",
    "# )\n",
    "# # Train model\n",
    "# xgb_model.fit(X_train, y_train, X_val, y_val, verbose=True)\n",
    "# # Predict\n",
    "# print(\"\\nMaking predictions...\")\n",
    "# y_pred_train_xgb = xgb_model.predict(X_train)\n",
    "# y_pred_val_xgb = xgb_model.predict(X_val)\n",
    "# # Calculate accuracy\n",
    "# train_accuracy_xgb = np.mean(y_pred_train_xgb == (y_train == 'spam').astype(int))\n",
    "# val_accuracy_xgb = np.mean(y_pred_val_xgb == (y_val == 'spam').astype(int))\n",
    "# print(f\"\\nImproved XGBoost Results:\")\n",
    "# print(f\"Validation Accuracy: {val_accuracy_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chisboiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
