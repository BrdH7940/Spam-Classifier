{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from NaiveBayes import MultinomialNB\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.drop(columns=['Message ID', 'Unnamed: 0', 'split'], inplace=True)\n",
    "\n",
    "df_val = pd.read_csv('val.csv')\n",
    "df_val.drop(columns=['Message ID', 'Unnamed: 0', 'split'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27284 entries, 0 to 27283\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Subject   27055 non-null  object\n",
      " 1   Message   26932 non-null  object\n",
      " 2   Spam/Ham  27284 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 639.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam/Ham\n",
      "spam    13858\n",
      "ham     13426\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Spam/Ham'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam/Ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christmas tree farm pictures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vastar resources , inc .</td>\n",
       "      <td>gary , production from the high island larger ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>- calpine daily gas nomination 1 . doc</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>re : issue</td>\n",
       "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcmullen gas for 11 / 99</td>\n",
       "      <td>jackie ,\\nsince the inlet to 3 river plant is ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "0  christmas tree farm pictures   \n",
       "1      vastar resources , inc .   \n",
       "2  calpine daily gas nomination   \n",
       "3                    re : issue   \n",
       "4      mcmullen gas for 11 / 99   \n",
       "\n",
       "                                             Message Spam/Ham  \n",
       "0                                                NaN      ham  \n",
       "1  gary , production from the high island larger ...      ham  \n",
       "2             - calpine daily gas nomination 1 . doc      ham  \n",
       "3  fyi - see note below - already done .\\nstella\\...      ham  \n",
       "4  jackie ,\\nsince the inlet to 3 river plant is ...      ham  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 27284\n",
      "Number of rows: 3084\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {len(df_train)}\")\n",
    "print(f\"Number of rows: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training set:\n",
      "Subject     229\n",
      "Message     352\n",
      "Spam/Ham      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in validation set:\n",
      "Subject     29\n",
      "Message     35\n",
      "Spam/Ham     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(\"\\nMissing values in training set:\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"\\nMissing values in validation set:\")\n",
    "print(df_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any NaN values with empty strings\n",
    "df_train['Subject'] = df_train['Subject'].fillna('')\n",
    "df_train['Message'] = df_train['Message'].fillna('')\n",
    "df_val['Subject'] = df_val['Subject'].fillna('')\n",
    "df_val['Message'] = df_val['Message'].fillna('')\n",
    "\n",
    "# Create Bag of Words vectorizer for text features\n",
    "bow = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Combine Subject and Message columns\n",
    "df_train['text'] = df_train['Subject'] + ' ' + df_train['Message']\n",
    "df_val['text'] = df_val['Subject'] + ' ' + df_val['Message']\n",
    "\n",
    "# Transform text data to BoW features\n",
    "X_train = bow.fit_transform(df_train['text'])\n",
    "X_val = bow.transform(df_val['text'])\n",
    "\n",
    "# Get labels\n",
    "y_train = df_train['Spam/Ham']\n",
    "y_val = df_val['Spam/Ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrices to dense arrays properly\n",
    "X_train = X_train.toarray()\n",
    "y_train = np.array(y_train)\n",
    "X_val = X_val.toarray()\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# # Implement Multinomial Naive Bayes from scratch\n",
    "# class MultinomialNB:\n",
    "#     def __init__(self, alpha=1.0):\n",
    "#         self.alpha = alpha  # Laplace smoothing parameter\n",
    "#         self.class_priors = None\n",
    "#         self.feature_probs = None\n",
    "#         self.classes = None\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         # Check if X is empty or 1-dimensional\n",
    "#         if X.size == 0:\n",
    "#             raise ValueError(\"Input array X is empty\")\n",
    "#         if len(X.shape) == 1:\n",
    "#             X = X.reshape(1, -1)\n",
    "            \n",
    "#         # Get shape, handling both sparse and dense matrices\n",
    "#         n_samples = X.shape[0]\n",
    "#         n_features = X.shape[1]\n",
    "            \n",
    "#         self.classes = np.unique(y)\n",
    "#         n_classes = len(self.classes)\n",
    "        \n",
    "#         # Calculate class priors P(y)\n",
    "#         self.class_priors = np.zeros(n_classes)\n",
    "#         for i, c in enumerate(self.classes):\n",
    "#             self.class_priors[i] = np.sum(y == c) / n_samples\n",
    "            \n",
    "#         # Calculate feature probabilities P(x|y) with Laplace smoothing\n",
    "#         # Process one class at a time to reduce memory usage\n",
    "#         self.feature_probs = np.zeros((n_classes, n_features))\n",
    "#         for i, c in enumerate(self.classes):\n",
    "#             # Get indices of samples belonging to current class\n",
    "#             class_indices = np.where(y == c)[0]\n",
    "            \n",
    "#             # Calculate feature counts in batches\n",
    "#             feature_counts = np.zeros(n_features) + self.alpha\n",
    "#             batch_size = 1000  # Adjust based on available memory\n",
    "            \n",
    "#             for start_idx in range(0, len(class_indices), batch_size):\n",
    "#                 end_idx = min(start_idx + batch_size, len(class_indices))\n",
    "#                 batch_indices = class_indices[start_idx:end_idx]\n",
    "                \n",
    "#                 # Sum features for current batch\n",
    "#                 if isinstance(X, np.ndarray):\n",
    "#                     batch_sum = X[batch_indices].sum(axis=0)\n",
    "#                 else:\n",
    "#                     batch_sum = X[batch_indices].toarray().sum(axis=0)\n",
    "                    \n",
    "#                 feature_counts += batch_sum\n",
    "                \n",
    "#             total_counts = feature_counts.sum()\n",
    "#             self.feature_probs[i] = feature_counts / total_counts\n",
    "            \n",
    "#     def predict(self, X):\n",
    "#         # Handle 1-dimensional input\n",
    "#         if len(X.shape) == 1:\n",
    "#             X = X.reshape(1, -1)\n",
    "            \n",
    "#         # Predict in batches to save memory\n",
    "#         predictions = []\n",
    "#         batch_size = 1000  # Adjust based on available memory\n",
    "        \n",
    "#         for start_idx in range(0, X.shape[0], batch_size):\n",
    "#             end_idx = min(start_idx + batch_size, X.shape[0])\n",
    "#             if isinstance(X, np.ndarray):\n",
    "#                 batch = X[start_idx:end_idx]\n",
    "#             else:\n",
    "#                 batch = X[start_idx:end_idx].toarray()\n",
    "                \n",
    "#             batch_predictions = np.array([self._predict_single(x) for x in batch])\n",
    "#             predictions.extend(batch_predictions)\n",
    "            \n",
    "#         return np.array(predictions)\n",
    "    \n",
    "#     def _predict_single(self, x):\n",
    "#         # Calculate log probabilities to prevent numerical underflow\n",
    "#         log_probs = np.log(self.class_priors)\n",
    "        \n",
    "#         # Add log of feature probabilities where feature is present (x > 0)\n",
    "#         for i in range(len(self.classes)):\n",
    "#             # Only consider non-zero features to save computation\n",
    "#             present_features = x > 0\n",
    "#             if np.any(present_features):\n",
    "#                 # Multiply probability by feature count (for multinomial)\n",
    "#                 log_probs[i] += np.sum(np.log(self.feature_probs[i][present_features]) * x[present_features])\n",
    "        \n",
    "#         # Return class with highest probability\n",
    "#         return self.classes[np.argmax(log_probs)]\n",
    "\n",
    "# Train the model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
